ML5

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import datetime as dt
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

# Load the dataset
df = pd.read_csv(r'C:\Users\Aastha\Downloads\sales_data_sample.csv', encoding='unicode_escape')

# Display the first few rows of the dataset
df.head()

# Check the dataset info and structure
df.info()

# Columns to remove as they are not relevant for clustering
to_drop = ['ADDRESSLINE1', 'ADDRESSLINE2', 'STATE', 'POSTALCODE', 'PHONE']
df = df.drop(to_drop, axis=1)

# Check for null values
print(df.isnull().sum())

# We are ignoring the 'territory' column as it's not relevant
# Display data types of the columns
df.dtypes

# Convert 'ORDERDATE' column to datetime format
df['ORDERDATE'] = pd.to_datetime(df['ORDERDATE'])

# Define snapshot_date as one day after the latest order date
snapshot_date = df['ORDERDATE'].max() + dt.timedelta(days=1)

# Create RFM (Recency, Frequency, Monetary) table
df_RFM = df.groupby(['CUSTOMERNAME']).agg({
    'ORDERDATE': lambda x: (snapshot_date - x.max()).days,  # Recency: days since last order
    'ORDERNUMBER': 'count',  # Frequency: count of orders
    'SALES': 'sum'  # MonetaryValue: total sales amount
})

# Rename the columns for clarity
df_RFM.rename(columns={
    'ORDERDATE': 'Recency',
    'ORDERNUMBER': 'Frequency',
    'SALES': 'MonetaryValue'
}, inplace=True)

# Display the first few rows of the RFM data
df_RFM.head()

# Create quantile-based segments for R, F, and M
df_RFM['M'] = pd.qcut(df_RFM['MonetaryValue'], q=4, labels=range(1, 5))  # MonetaryValue quartiles
df_RFM['R'] = pd.qcut(df_RFM['Recency'], q=4, labels=list(range(4, 0, -1)))  # Recency quartiles
df_RFM['F'] = pd.qcut(df_RFM['Frequency'], q=4, labels=range(1, 5))  # Frequency quartiles

# Create the RFM Score by summing the R, F, M values
df_RFM['RFM_Score'] = df_RFM[['R', 'M', 'F']].sum(axis=1)

# Create customer segments based on RFM Score
def rfm_level(df):
    if df['RFM_Score'] >= 10:
        return 'High Value Customer'
    elif 6 <= df['RFM_Score'] < 10:
        return 'Mid Value Customer'
    else:
        return 'Low Value Customer'

df_RFM['RFM_Level'] = df_RFM.apply(rfm_level, axis=1)

# Display the first few rows with the RFM Level
df_RFM.head()

# Select the features for clustering (Recency, Frequency, Monetary)
data = df_RFM[['Recency', 'Frequency', 'MonetaryValue']]
data.head()

# Perform log transformation to reduce skewness in data
data_log = np.log(data)
data_log.head()

# Standardize the data to have mean=0 and variance=1
scaler = StandardScaler()
scaler.fit(data_log)
data_normalized = scaler.transform(data_log)
data_normalized = pd.DataFrame(data_normalized, index=data_log.index, columns=data_log.columns)

# Display summary statistics of the normalized data
data_normalized.describe().round(2)

# Use the Elbow Method to determine the optimal number of clusters
sse = {}

# Test for different values of K (from 1 to 20)
for k in range(1, 21):
    kmeans = KMeans(n_clusters=k, random_state=1)
    kmeans.fit(data_normalized)
    sse[k] = kmeans.inertia_

# Plot the Elbow curve
plt.figure(figsize=(10, 6))
plt.title('The Elbow Method')
plt.xlabel('Number of Clusters (K)')
plt.ylabel('Sum of Squared Errors (SSE)')
plt.style.use('ggplot')

sns.pointplot(x=list(sse.keys()), y=list(sse.values()))
plt.text(4.5, 60, "Largest Angle", bbox=dict(facecolor='lightgreen', alpha=0.5))
plt.show()

# From the Elbow plot, it seems that K=5 is a good choice (where the curve flattens)

# Fit KMeans with 5 clusters (based on the Elbow method result)
kmeans = KMeans(n_clusters=5, random_state=1)
kmeans.fit(data_normalized)

# Assign the cluster labels to the data
cluster_labels = kmeans.labels_

# Add the cluster labels to the RFM data
data_rfm = data.assign(Cluster=cluster_labels)
data_rfm.head()

# Optionally, you can analyze the clusters by viewing the centroids
cluster_centroids = pd.DataFrame(kmeans.cluster_centers_, columns=data.columns)
print(cluster_centroids)

# You can now visualize the clusters or analyze the segments
